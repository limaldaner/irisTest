{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################################################################\n",
    "#        3 Machine Learning algorithms evaluation with iris dataset\n",
    "#\n",
    "# France\n",
    "# November 2019\n",
    "#\n",
    "# Oriented by: Dr. R. Possamai and Ms. M. Trindade\n",
    "# Author: Li√©ge Maldaner\n",
    "# E-mail: liege.malda@gmail.com\n",
    "#\n",
    "#\n",
    "# Results:\n",
    "###########################################################################\n",
    "\n",
    "# Packages\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import _pickle as plk\n",
    "import os\n",
    "from io import StringIO\n",
    "import pylab as plt\n",
    "from glob import glob\n",
    "import argparse\n",
    "#import progressbar\n",
    "from numpy.lib import stride_tricks\n",
    "from skimage import feature\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import mahotas as mt\n",
    "import random\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_args(args):\n",
    "\n",
    "    if args.classifier != \"SVM\" and args.classifier != \"RF\" and args.classifier != \"GBC\":\n",
    "        raise ValueError(\"Classifier must be either SVM, RF or GBC\")\n",
    "\n",
    "    return args\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-c\", \"--classifier\", help=\"Classification model to use\", required = True)\n",
    "    parser.add_argument(\"-o\", \"--output_model\", help=\"Path to save model. Must end in .p\", required = True)\n",
    "    args = parser.parse_args()\n",
    "    return check_args(args)\n",
    "\n",
    "def read_data():\n",
    "\n",
    "    print ('[INFO] Reading image data.')\n",
    "\n",
    "    iris = load_iris()\n",
    "    #feature_names = iris.feature_names\n",
    "    classes = iris.target\n",
    "    features = iris.data\n",
    "    \n",
    "    return features, classes\n",
    "\n",
    "def dataset(features, classes):   \n",
    "    print ('[INFO] Creating training dataset.')\n",
    "\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    \n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    \n",
    "    TEST_PERC = 0.10\n",
    "    VAL_PERC = 0.10\n",
    "    TRAIN_PERC = 0.90\n",
    "    \n",
    "    totalNum = len(features)\n",
    "    testNum = int(TEST_PERC * totalNum)\n",
    "    valNum = int(VAL_PERC * totalNum)\n",
    "    trainNum = int(TRAIN_PERC * totalNum)\n",
    "    \n",
    "    index = np.arange(len(features))\n",
    "    random_train =  np.random.choice(index,trainNum)\n",
    "    random_test = np.random.choice(index,testNum)\n",
    "    random_val = np.random.choice(index,valNum)\n",
    "    \n",
    "    X_train = features[random_train]\n",
    "    X_test = features[random_test]\n",
    "    X_val = features[random_val]\n",
    "    \n",
    "    y_train = classes[random_train]\n",
    "    y_test = classes[random_test]\n",
    "    y_val = classes[random_val]\n",
    "    #for i in enumerate(features):\n",
    "    #    .append(features)\n",
    "        \n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, classifier):\n",
    "\n",
    "    if classifier == \"SVM\":\n",
    "        from sklearn.svm import SVC\n",
    "        print ('[INFO] Training Support Vector Machine model.')\n",
    "        model = SVC()\n",
    "        model.fit(X, y)\n",
    "    elif classifier == \"RF\":\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        print ('[INFO] Training Random Forest model.')\n",
    "        model = RandomForestClassifier(n_estimators=250, max_depth=12, random_state=42)\n",
    "        # n_estimators = The number of trees in the forest;\n",
    "        # max_depth = The maximum depth of the tree. If None, then nodes are expanded\n",
    "        #until all leaves are pure or until all leaves contain less than min_samples_split samples;\n",
    "        # random_state = If int, random_state is the seed used by the random number generator; \n",
    "        model.fit(X, y)\n",
    "    elif classifier == \"GBC\":\n",
    "        from sklearn.ensemble import GradientBoostingClassifier\n",
    "        model = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "        # learning_rate = learning rate shrinks the contribution of each tree by learning_rate. \n",
    "        #There is a trade-off between learning_rate and n_estimators;\n",
    "        model.fit(X, y)\n",
    "\n",
    "    print ('[INFO] Model training complete.')\n",
    "    print ('[INFO] Training Accuracy: %.2f' %model.score(X, y))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X, y, model):\n",
    "\n",
    "    pred = model.predict(X)\n",
    "    precision = metrics.precision_score(y, pred, average='weighted', labels=np.unique(pred))\n",
    "    recall = metrics.recall_score(y, pred, average='weighted', labels=np.unique(pred))\n",
    "    f1 = metrics.f1_score(y, pred, average='weighted', labels=np.unique(pred))\n",
    "    accuracy = metrics.accuracy_score(y, pred)\n",
    "\n",
    "    print ('--------------------------------')\n",
    "    print('Confusion Matrix')\n",
    "    print(confusion_matrix(y, pred))\n",
    "    \n",
    "    print ('--------------------------------')\n",
    "    print ('[RESULTS] Accuracy: %.2f' %accuracy)\n",
    "    print ('[RESULTS] Precision: %.2f' %precision)\n",
    "    print ('[RESULTS] Recall: %.2f' %recall)\n",
    "    print ('[RESULTS] F1: %.2f' %f1)\n",
    "    print ('--------------------------------')    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(classifier):\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    features, classes = read_data()\n",
    "    X_train, X_test, X_val, y_train, y_test, y_val = dataset(features, classes)\n",
    "    model = train_model(X_train, y_train, classifier)\n",
    "    test_model(X_test, y_test, model)\n",
    "    #pkl.dump(model, open(output_model, \"wb\"))\n",
    "    print ('Processing time:',time.time()-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading image data.\n",
      "[INFO] Creating training dataset.\n",
      "[INFO] Model training complete.\n",
      "[INFO] Training Accuracy: 1.00\n",
      "--------------------------------\n",
      "Confusion Matrix\n",
      "[[6 0 0]\n",
      " [0 2 1]\n",
      " [0 1 5]]\n",
      "--------------------------------\n",
      "[RESULTS] Accuracy: 0.87\n",
      "[RESULTS] Precision: 0.87\n",
      "[RESULTS] Recall: 0.87\n",
      "[RESULTS] F1: 0.87\n",
      "--------------------------------\n",
      "Processing time: 0.10964107513427734\n"
     ]
    }
   ],
   "source": [
    "main('GBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading image data.\n",
      "[INFO] Creating training dataset on %d image(s).\n",
      "[INFO] Training Random Forest model.\n",
      "[INFO] Model training complete.\n",
      "[INFO] Training Accuracy: 1.00\n",
      "--------------------------------\n",
      "Confusion Matrix\n",
      "[[7 0 0]\n",
      " [0 2 0]\n",
      " [0 1 5]]\n",
      "--------------------------------\n",
      "[RESULTS] Accuracy: 0.93\n",
      "[RESULTS] Precision: 0.96\n",
      "[RESULTS] Recall: 0.93\n",
      "[RESULTS] F1: 0.94\n",
      "--------------------------------\n",
      "Processing time: 0.2927107810974121\n"
     ]
    }
   ],
   "source": [
    "main('RF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Reading image data.\n",
      "[INFO] Creating training dataset on %d image(s).\n",
      "[INFO] Training Support Vector Machine model.\n",
      "[INFO] Model training complete.\n",
      "[INFO] Training Accuracy: 1.00\n",
      "--------------------------------\n",
      "Confusion Matrix\n",
      "[[2 0 0]\n",
      " [0 9 0]\n",
      " [0 0 4]]\n",
      "--------------------------------\n",
      "[RESULTS] Accuracy: 1.00\n",
      "[RESULTS] Precision: 1.00\n",
      "[RESULTS] Recall: 1.00\n",
      "[RESULTS] F1: 1.00\n",
      "--------------------------------\n",
      "Processing time: 0.009836196899414062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/liegemaldaner/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "main('SVM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
